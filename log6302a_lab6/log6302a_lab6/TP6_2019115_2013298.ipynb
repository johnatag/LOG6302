{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Global variable - directory where cfg.json and .dot files generated by our code will be stored \n",
    "part1_output_directory = \"output/part_1/\"\n",
    "part2_output_directory = \"output/part_2/\"\n",
    "\n",
    "# Utility functions taken from TP1\n",
    "def get_json_files(extension, directory):\n",
    "   directory = Path(directory)\n",
    "   return [str(file) for file in directory.rglob(extension)]\n",
    "\n",
    "def create_output_file(filename, directory):\n",
    "    # Check if output directory exists, if not, create it\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Check if output file already exists, if so, delete and create new file\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "    # Open in \"append\" mode to avoid overwriting the whole file after each modification\n",
    "    return open(directory + filename, \"a\")\n",
    "\n",
    "def close_output_file(file):\n",
    "   file.close()\n",
    "\n",
    "# The following function has been adapted from the following sources:\n",
    "## https://www.tutorialspoint.com/How-to-scan-through-a-directory-recursively-in-Python\n",
    "## https://bito.ai/resources/unzip-gz-file-python-python-explained/\n",
    "## https://stackoverflow.com/questions/42445831/python-3-creating-files-in-relative-directories\n",
    "def extract_zipped_files(source_directory, target_directory):\n",
    "    # Check if target directory exists, if not, create it\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory)\n",
    "\n",
    "    # Use os.walk to recursively visit the source folder\n",
    "    for current_dir, dir_names, file_names in os.walk(source_directory):\n",
    "        for filename in file_names:\n",
    "            # Find all zipped files\n",
    "            if filename.endswith('.gz'):\n",
    "                # Construct source path from source directory and the filename\n",
    "                source_path = os.path.join(current_dir, filename)\n",
    "\n",
    "                # Construct target path by replacing the source directory with target directory\n",
    "                target_rel_path = os.path.relpath(current_dir, source_directory)\n",
    "                target_dir = os.path.join(target_directory, target_rel_path)\n",
    "                target_path = os.path.join(target_dir, filename[:-3])\n",
    "                \n",
    "                # Check if target directory exists, if not, create it (this is for the target directories within the main directory)\n",
    "                if not os.path.exists(target_dir):\n",
    "                    os.makedirs(target_dir)\n",
    "                \n",
    "                # Open and extract zipped files\n",
    "                with gzip.open(source_path, 'rb') as f_in:\n",
    "                    with open(target_path, 'wb') as f_out:\n",
    "                        shutil.copyfileobj(f_in, f_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output file and reader\n",
    "from code_analysis import ASTReader\n",
    "reader = ASTReader ()\n",
    "\n",
    "def find_similar_files(directory):\n",
    "    # Prepare output file\n",
    "    part1_output_directory = \"output/part_1/\"\n",
    "    # part_1_output_file = create_output_file(\"part_1_output_file.txt\", part1_output_directory)\n",
    "\n",
    "    # Prepare output arrays (we decided agains using a dictionnary for efficiency, a dict with 900 elements seemed to cause the program to be slower)\n",
    "    ## We assumed that since we are populating these arrays at the same time and are not modifying them after, the same index in both arrays should\n",
    "    ## point to the same file.\n",
    "    filename_array = []\n",
    "    vector_array = []\n",
    "\n",
    "    # Retrieve filenames of all ast in the specified directory\n",
    "    astFilenames = get_json_files('*.ast.json', directory)\n",
    "\n",
    "    # Iterate over the filenames array once to visit all cfgs\n",
    "    for filename in astFilenames:\n",
    "        # Load ast in memory\n",
    "        ast = reader.read_ast(filename)\n",
    "\n",
    "        if len(ast.get_node_ids()) > 100:\n",
    "            print(filename)\n",
    "            vector = ast.vectorize()\n",
    "\n",
    "    # close_output_file(part_1_output_file)\n",
    "            \n",
    "source_dir = './ast'\n",
    "target_dir = './extracted_ast'\n",
    "extract_zipped_files(source_dir, target_dir)\n",
    "find_similar_files(target_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
