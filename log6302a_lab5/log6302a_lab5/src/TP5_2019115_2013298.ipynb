{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authors\n",
    "\n",
    "- Ikram Kohil, 2019115\n",
    "- Johnatan Gao, 2013298"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taint Analysis\n",
    "In this lab, we will be implementing taint analysis to ensure that all data coming from the outside (user inputs) do not reach critical parts of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementation and tests\n",
    "\n",
    "In this first part we will implement the teint analysis algorithm called: Possibly Teinted Definitions. We will then test the implementation on four examples in the folder **part_1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Possibly Tainted Definitions\n",
    "\n",
    "According to class notes, there are a couple of variables/concepts that we need to define in order to implement the conceptual algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "in\\_taintedDefs: V → \\Rho(DEFS)\n",
    "$$\n",
    "$$\n",
    "out\\_taintedDefs: V → \\Rho(DEFS)\n",
    "$$\n",
    "\n",
    "In this statement:\n",
    "\n",
    "- V: This typically represents a set or type of variables within the context of a programming language or a system. Variables can be anything from integers, strings, objects, etc., depending on the language or system under consideration.\n",
    "- P(DEFS): P represents the power set, which is the set of all subsets of a given set. DEFS is a set of definitions. So, P(DEFS) would be the power set of the set of definitions. In this context, it suggests that for each variable in V, there is a set of definitions (DEFS) associated with it, and in_taintedDefs maps each variable in V to a subset of its associated definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "in\\_taintedDefs(v) = \\bigcup_{p \\in preds(node)} out\\_taintedDefs(p)\n",
    "$$\n",
    "\n",
    "This equation defines the behavior of the in_taintedDefs function. It states that the in_taintedDefs for a variable v is the union (⋃) of the out_taintedDefs for all predecessors (preds(node)) of a given node. In other words, to compute the in_taintedDefs for a variable at a particular node, you take the union of the out_taintedDefs for all nodes that flow into that node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "tainted\\_GEN[node] = \n",
    "\\left\\{\n",
    "  \\begin{array}{ll}\n",
    "    \\ {d_i \\in defs[node]  | \\exists(d_j, r_k) \\in defRefChains | (r_k \\in refs[node]), (d_j \\in in\\_tainted[node])} &\\text{ if } (node \\in EXPR)\\ \\\\\n",
    "\n",
    "    \\ {d_i \\in defs[node]} & \\text{ if } (node \\in SOURCES) \\\\\n",
    "\n",
    "    \\emptyset & \\text{ if } (node \\in FILTERS) \\\\\n",
    "    \n",
    "    \\emptyset & \\text{ if } (node \\in SAFESET)\n",
    "  \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "In this statement, we are trying to populate our GEN array. For each node in our CFG, we check for four conditions:\n",
    "- If the node is part of the FILTERS set, then the tainted_gen for this node is empty\n",
    "- If the node is part of the SAFESET set, then the tainted_gen for this node is empty as well\n",
    "- If the node is part of the SOURCES set, then the tainted_gen for this node is the definition for this node\n",
    "- If the node is part of the EXPR set (in other words, is an expression), then we will:\n",
    "  - Take the defintion for this node, if it exists\n",
    "  - Take the definition/reference pair for this node, if it exists\n",
    "  - Create a pair of (reference, definition), if the reference is part of our reference set and definition is part of the in_tainted set for this node\n",
    "  \n",
    "In other words, \n",
    "1. Check if node is a definition: First, determine if the current node is a definition.\n",
    "\n",
    "2. If the node is a definition and the right side is a source: If the node is indeed a definition, and its right side is a source, then mark the definition as tainted. This means that the definition corresponds to a value that is considered tainted or untrusted.\n",
    "\n",
    "3. If the node is a definition and it corresponds to a filter or safe: If the node is a definition but corresponds to a filter or safe, then no action is taken. This implies that the definition is associated with a value that is considered safe or filtered, so it doesn't need further processing.\n",
    "\n",
    "4. If the node is a definition and the right side is an expression: If the node is a definition and its right side is an expression, further investigation is needed.\n",
    "Check if any references in the expression are tainted: Examine all references in the expression associated with the definition. If any of these references are tainted (i.e., marked as untrusted), then the definition is also considered tainted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "tainted\\_KILL[node] = {d_k | (var(d_k) = var(d_m)) \\land (d_m \\in defs[node] )}\n",
    "$$\n",
    "\n",
    "In this statement, we are trying to populate the kill set. Essentially, everytime we detect a definition OR a redefinition, we must add it to our tainted_kill set for this particular node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the conceptual algorithm for Possibly-Tainted Definitions:\n",
    "\n",
    "```python\n",
    "def POSS_TAINTED_DEFS():\n",
    "    for all node ∈ nodeSet do\n",
    "        IN[node] = /0\n",
    "        OUT[node] = /0\n",
    "    end for\n",
    "\n",
    "    changes = True\n",
    "\n",
    "    while changes do\n",
    "        changes = False\n",
    "        for all node ∈ nodeSet do\n",
    "\n",
    "            IN[node] = ⋃_(p∈preds(node)) OUT(p)\n",
    "            old OUT[node] = OUT[node]\n",
    "            OUT[node] = GEN[node] ∪ (IN[node] - KILL[node])\n",
    "\n",
    "            if OUT[node] != old_OUT[node] then\n",
    "                changes = True\n",
    "            end if\n",
    "        end for\n",
    "    end while\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Global variable - directory where cfg.json and .dot files generated by our code will be stored \n",
    "part1_output_directory = \"output/part_1/\"\n",
    "part2_output_directory = \"output/part_2/\"\n",
    "\n",
    "def get_json_files(pattern: str, directory: str):\n",
    "   \"\"\"\n",
    "    Finds all files in the specified directory and its subdirectories that match the given pattern.\n",
    "\n",
    "    This function uses the glob module to search for files that match the specified pattern.\n",
    "    The pattern can include wildcards like '*' to match any sequence of characters and '?' to match any single character.\n",
    "\n",
    "    Args:\n",
    "        pattern (str): The pattern to match filenames against. For example, '*.json' to match all JSON files.\n",
    "        directory (str): The directory to search in. This can be an absolute path or a relative path.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of file paths that match the given pattern. Each path is a string.\n",
    "\n",
    "    Example:\n",
    "        >>> get_json_files('*.json', '/path/to/directory')\n",
    "        ['/path/to/directory/file1.json', '/path/to/directory/subdir/file2.json']\n",
    "    \"\"\"\n",
    "   files = glob.glob(f\"{directory}/**/{pattern}\", recursive=True)\n",
    "   print(files)\n",
    "   return files\n",
    "\n",
    "def splitext_recurse(p):\n",
    "    \"\"\"\n",
    "    Recursively splits the filename into base name and extensions.\n",
    "    \n",
    "    Args:\n",
    "        p: The filename to split.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple containing the base name and all extensions.\n",
    "    \"\"\"\n",
    "    base, ext = os.path.splitext(p)\n",
    "    if ext == '':\n",
    "        return (base,)\n",
    "    else:\n",
    "        return splitext_recurse(base) + (ext,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Set\n",
    "import os\n",
    "import json\n",
    "from code_analysis import CFGReader\n",
    "from code_analysis import ASTReader\n",
    "\n",
    "class TaintAnalysisAlgorithm:\n",
    "    \"\"\"\n",
    "    A class for performing taint analysis on a given file.\n",
    "    \n",
    "    Attributes:\n",
    "        cfg: The control flow graph (CFG) of the file.\n",
    "        ast: The abstract syntax tree (AST) of the file.\n",
    "        filename: The name of the file being analyzed.\n",
    "        filepath: The path to the file being analyzed.\n",
    "        taint_file_data: The data loaded from the taint file.\n",
    "        tainted_params: A dictionary containing all necessary parameters for taint analysis.\n",
    "        tainted_gen: A dictionary containing all tainted_gen nodes.\n",
    "        tainted_kill: A dictionary containing all tainted_kill nodes.\n",
    "        tainted_in: A dictionary containing all tainted_in nodes.\n",
    "        tainted_out: A dictionary containing all tainted_out nodes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filepath: str):\n",
    "        \"\"\"\n",
    "        Initializes the TaintAnalysisAlgorithm with the given filepath and filename.\n",
    "\n",
    "        We are initializing all the necessary variables to perform a taint analysis.\n",
    "        \n",
    "        Args:\n",
    "            filepath: The path to the directory containing the file.\n",
    "            filename: The name of the file to analyze.\n",
    "        \"\"\"\n",
    "        self.cfg = CFGReader().read_cfg(f\"{filepath}.php.cfg.json\")\n",
    "        self.ast = ASTReader().read_ast(f\"{filepath}.php.ast.json\")\n",
    "        self.filepath = filepath\n",
    "\n",
    "        with open(f\"{filepath}.php.taint.json\") as taint_file:\n",
    "            self.taint_file_data = json.load(taint_file)\n",
    "\n",
    "        self.tainted_params: Dict[str, List[int]] = {\n",
    "            \"defs\": self.taint_file_data['defs'],\n",
    "            \"refs\": self.taint_file_data['refs'],\n",
    "            \"pairs\" : self.taint_file_data['pairs'],\n",
    "            \"sinks\" : self.taint_file_data['sinks'],\n",
    "            \"filters\" : self.taint_file_data['filters'],\n",
    "            \"safes\" : self.taint_file_data['safes'],\n",
    "            \"sources\" : self.taint_file_data['sources']\n",
    "        }\n",
    "\n",
    "        self.tainted_gen: Dict[int, Set] = {}\n",
    "        self.tainted_kill: Dict[int, Set] = {}\n",
    "        self.tainted_in: Dict[int, Set] = {}\n",
    "        self.tainted_out: Dict[int, Set] = {}\n",
    "\n",
    "        for node in self.cfg.get_node_ids():\n",
    "            self.tainted_in[node] = set()\n",
    "            self.tainted_out[node] = set()\n",
    "            self.tainted_gen[node] = set()\n",
    "            self.tainted_kill[node] = set()\n",
    "\n",
    "    def __is_binOp_equal(self, node_id: int) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the node is a binary operation equal to '='.\n",
    "        \n",
    "        Args:\n",
    "            node_id: The ID of the node to check.\n",
    "        \n",
    "        Returns:\n",
    "            True if the node is a binary operation equal to '=', False otherwise.\n",
    "        \"\"\"\n",
    "        return self.cfg.get_type(node_id) == \"BinOP\" and self.cfg.get_image(node_id) == \"=\"\n",
    "\n",
    "    def __get_expr_nodes(self, node: int) -> List[int]:\n",
    "        \"\"\"\n",
    "        Retrieves all expression nodes from the given node.\n",
    "        \n",
    "        Args:\n",
    "            node: The starting node ID.\n",
    "        \n",
    "        Returns:\n",
    "            A list of node IDs representing the expression nodes.\n",
    "        \"\"\"\n",
    "        ref = []\n",
    "        stack = [node]\n",
    "\n",
    "        while stack:\n",
    "            current_node = stack.pop()\n",
    "            node_type = self.cfg.get_type(current_node)\n",
    "\n",
    "            if node_type == 'BinOP':\n",
    "                operands = self.cfg.get_op_hands(current_node)\n",
    "                stack.extend(operands)\n",
    "            else:\n",
    "                ref.append(current_node)\n",
    "\n",
    "        return ref\n",
    "    \n",
    "    def _get_tainted_gen(self, node_id: int):\n",
    "        \"\"\"\n",
    "        Determines the tainted_gen nodes for a given node.\n",
    "\n",
    "        Here, we are essentially following the statement defined for tainted_GEN by\n",
    "        handling what happens with the expression is part of the sources, safes and filters set.\n",
    "        We determine that if the node is a \"=\", and that it's not part of the previously mentionned sets,\n",
    "        it must be an expression.\n",
    "        \n",
    "        Args:\n",
    "            node_id: The ID of the node to analyze.\n",
    "        \"\"\"\n",
    "        if self.__is_binOp_equal(node_id):\n",
    "            var_node_id, expr_node_id = self.cfg.get_op_hands(node_id)\n",
    "            if expr_node_id in self.tainted_params[\"sources\"]:\n",
    "                var_node_id = self.cfg.get_op_hands(node_id)[0]\n",
    "                self.tainted_gen[node_id].add(var_node_id)\n",
    "            elif expr_node_id in self.tainted_params[\"safes\"]:\n",
    "                self.tainted_gen[node_id] = set()\n",
    "            elif expr_node_id in self.tainted_params[\"filters\"]:\n",
    "                self.tainted_gen[node_id] = set()\n",
    "            else:\n",
    "                refExpr = self.__get_expr_nodes(expr_node_id)\n",
    "                for ref in refExpr:\n",
    "                    for defRef in self.tainted_params[\"pairs\"]:\n",
    "                        definition, reference = defRef\n",
    "                        if reference == ref and definition in self.tainted_in[node_id]:\n",
    "                            self.tainted_gen[node_id].add(var_node_id)\n",
    "                            break\n",
    "            \n",
    "    def _get_tainted_kills(self, node_id: int):\n",
    "        \"\"\"\n",
    "        Determines the tainted_kill nodes for a given node.\n",
    "        \n",
    "        Args:\n",
    "            node_id: The ID of the node to analyze.\n",
    "        \"\"\"\n",
    "        if self.__is_binOp_equal(node_id):\n",
    "            var_node_id = self.cfg.get_op_hands(node_id)[0]\n",
    "            if var_node_id in self.tainted_params['defs']:\n",
    "                self.tainted_kill[node_id].add(var_node_id) \n",
    "\n",
    "    def _update_tainted_in(self, node_id: int):\n",
    "        \"\"\"\n",
    "        Updates the tainted_in nodes for a given node.\n",
    "\n",
    "        The reason why we do the condition for 'CallEnd' is due to the fact that the\n",
    "        parent of CallEnd is not the desired outcome.\n",
    "        \n",
    "        Args:\n",
    "            node_id: The ID of the node to update.\n",
    "        \"\"\"\n",
    "        predecessors = [self.cfg.get_call_begin(node_id)] if self.cfg.get_type(node_id) == 'CallEnd' else self.cfg.get_parents(node_id)\n",
    "        for predNode in predecessors:\n",
    "            self.tainted_in[node_id] = self.tainted_in[node_id].union(self.tainted_out[predNode])\n",
    "\n",
    "    def _perform_taint_analysis(self):\n",
    "        \"\"\"\n",
    "        Performs the taint analysis on the file.\n",
    "        \"\"\"\n",
    "        old_OUT = {}\n",
    "        changes = True\n",
    "        \n",
    "        while changes:\n",
    "            changes = False\n",
    "\n",
    "            for node in self.cfg.get_node_ids():\n",
    "                self._get_tainted_gen(node)                  \n",
    "                self._get_tainted_kills(node)                \n",
    "                self._update_tainted_in(node)\n",
    "\n",
    "                old_OUT[node] = self.tainted_out[node]\n",
    "\n",
    "                self.tainted_out[node] = self.tainted_gen[node].union(self.tainted_in[node].difference(self.tainted_kill[node]))\n",
    "\n",
    "                if self.tainted_out[node] != old_OUT[node]:\n",
    "                    changes = True\n",
    "\n",
    "    def output_results(self, directory: str, file_name: str):\n",
    "        \"\"\"\n",
    "        Outputs the results of the taint analysis to a file.\n",
    "        \n",
    "        Args:\n",
    "            directory: The directory where the output file should be saved.\n",
    "            file_name: The name of the output file.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        \n",
    "        output_file_path = f\"{directory}/{file_name}\"\n",
    "        self._perform_taint_analysis()\n",
    "        \n",
    "        with open(output_file_path, 'a+') as output_file:\n",
    "            output_file.write(f\"------------------------ File: {self.filepath} ------------------------\\n\")\n",
    "            for sink in self.tainted_params['sinks']:\n",
    "                for pair in self.tainted_params['pairs']:\n",
    "                    definition, reference = pair\n",
    "                    if sink == reference and definition in self.tainted_in[sink]:\n",
    "                        output_file.write(f\"'{self.cfg.get_image(definition)}' that's defined at line {self.ast.get_position(self.cfg.get_node_ast_ptr(definition))[0]} and referenced at line {self.ast.get_position(self.cfg.get_node_ast_ptr(reference))[0]} is tainted \\n\")\n",
    "\n",
    "            for node in self.cfg.get_node_ids():\n",
    "                output_file.write(f\"{node}: , IN: {self.tainted_in[node]}, OUT: {self.tainted_out[node]}\\n\")\n",
    "            output_file.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_part_1(directory):\n",
    "    part1_output_directory = \"output/part_1\"\n",
    "    part_1_output_file = \"part_1_output_file.txt\"\n",
    "\n",
    "    # Retrieve filenames of all php files in the specified directory\n",
    "    php_filenames = get_json_files('*.php', directory)\n",
    "\n",
    "    # Iterate over the filenames array once to visit all cfgs\n",
    "    for php_filename in php_filenames:\n",
    "        filename = splitext_recurse(php_filename)[0]\n",
    "        analyser = TaintAnalysisAlgorithm(filename)\n",
    "        analyser.output_results(part1_output_directory, part_1_output_file)\n",
    "\n",
    "directory_to_analyze = \"../part_1/\"\n",
    "analyze_part_1(directory_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_part_2(directory):\n",
    "    part2_output_directory = \"output/part_2\"\n",
    "    part2_output_file = \"part_2_output_file.txt\"\n",
    "\n",
    "    # Retrieve filenames of all cfg in the specified directory\n",
    "    cfg_filenames = get_json_files('*.php.cfg.json', directory)\n",
    "\n",
    "    for cfg_filename in cfg_filenames:\n",
    "        filename = splitext_recurse(cfg_filename)[0]\n",
    "        analyser = TaintAnalysisAlgorithm(filename)\n",
    "        analyser.output_results(part2_output_directory, part2_output_file)\n",
    "\n",
    "directory_to_analyze = \"../part_2/app.cfg\"\n",
    "analyze_part_2(directory_to_analyze)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
