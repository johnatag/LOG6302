{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authors\n",
    "\n",
    "- Ikram Kohil, 2019115\n",
    "- Johnatan Gao, 2013298"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taint Analysis\n",
    "In this lab, we will be implementing taint analysis to ensure that all data coming from the outside (user inputs) do not reach critical parts of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementation and tests\n",
    "\n",
    "In this first part we will implement the teint analysis algorithm called: Possibly Teinted Definitions. We will then test the implementation on four examples in the folder **part_1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Possibly Tainted Definitions\n",
    "\n",
    "According to class notes, there are a couple of variables/concepts that we need to define in order to implement the conceptual algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "in\\_taintedDefs: V → \\Rho(DEFS)\n",
    "$$\n",
    "$$\n",
    "out\\_taintedDefs: V → \\Rho(DEFS)\n",
    "$$\n",
    "\n",
    "In this statement:\n",
    "\n",
    "- V: This typically represents a set or type of variables within the context of a programming language or a system. Variables can be anything from integers, strings, objects, etc., depending on the language or system under consideration.\n",
    "- P(DEFS): P represents the power set, which is the set of all subsets of a given set. DEFS is a set of definitions. So, P(DEFS) would be the power set of the set of definitions. In this context, it suggests that for each variable in V, there is a set of definitions (DEFS) associated with it, and in_taintedDefs maps each variable in V to a subset of its associated definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "in\\_taintedDefs(v) = \\bigcup_{p \\in preds(node)} out\\_taintedDefs(p)\n",
    "$$\n",
    "\n",
    "This equation defines the behavior of the in_taintedDefs function. It states that the in_taintedDefs for a variable v is the union (⋃) of the out_taintedDefs for all predecessors (preds(node)) of a given node. In other words, to compute the in_taintedDefs for a variable at a particular node, you take the union of the out_taintedDefs for all nodes that flow into that node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "tainted\\_GEN[node] = \n",
    "\\left\\{\n",
    "  \\begin{array}{ll}\n",
    "    \\ {d_i \\in defs[node]  | \\exists(d_j, r_k) \\in defRefChains | (r_k \\in refs[node]), (d_j \\in in\\_tainted[node])} &\\text{ if } (node \\in EXPR)\\ \\\\\n",
    "\n",
    "    \\ {d_i \\in defs[node]} & \\text{ if } (node \\in SOURCES) \\\\\n",
    "\n",
    "    \\emptyset & \\text{ if } (node \\in FILTERS) \\\\\n",
    "    \n",
    "    \\emptyset & \\text{ if } (node \\in SAFESET)\n",
    "  \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "In this statement, we are trying to populate our GEN array. For each node in our CFG, we check for four conditions:\n",
    "- If the node is part of the FILTERS set, then the tainted_gen for this node is empty\n",
    "- If the node is part of the SAFESET set, then the tainted_gen for this node is empty as well\n",
    "- If the node is part of the SOURCES set, then the tainted_gen for this node is the definition for this node\n",
    "- If the node is part of the EXPR set (in other words, is an expression), then we will:\n",
    "  - Take the defintion for this node, if it exists\n",
    "  - Take the definition/reference pair for this node, if it exists\n",
    "  - Create a pair of (reference, definition), if the reference is part of our reference set and definition is part of the in_tainted set for this node\n",
    "  \n",
    "In other words, \n",
    "1. Check if node is a definition: First, determine if the current node is a definition.\n",
    "\n",
    "2. If the node is a definition and the right side is a source: If the node is indeed a definition, and its right side is a source, then mark the definition as tainted. This means that the definition corresponds to a value that is considered tainted or untrusted.\n",
    "\n",
    "3. If the node is a definition and it corresponds to a filter or safe: If the node is a definition but corresponds to a filter or safe, then no action is taken. This implies that the definition is associated with a value that is considered safe or filtered, so it doesn't need further processing.\n",
    "\n",
    "4. If the node is a definition and the right side is an expression: If the node is a definition and its right side is an expression, further investigation is needed.\n",
    "Check if any references in the expression are tainted: Examine all references in the expression associated with the definition. If any of these references are tainted (i.e., marked as untrusted), then the definition is also considered tainted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "tainted\\_KILL[node] = {d_k | (var(d_k) = var(d_m)) ^ (d_m \\in defs[node] )}\n",
    "$$\n",
    "\n",
    "In this statement, we are trying to populate the kill set. Essentially, everytime we detect a definition OR a redefinition, we must add it to our tainted_kill set for this particular node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from code_analysis import CFGReader\n",
    "from code_analysis import CFG\n",
    "\n",
    "# Global variable - directory where cfg.json and .dot files generated by our code will be stored \n",
    "part1_output_directory = \"output/part_1/\"\n",
    "part2_output_directory = \"output/part_2/\"\n",
    "\n",
    "# Utility functions taken from TP1\n",
    "def get_json_files(extension, directory):\n",
    "   directory = Path(directory)\n",
    "   return [str(file) for file in directory.rglob(extension)]\n",
    "\n",
    "def create_output_file(filename, directory):\n",
    "    # Check if output directory exists, if not, create it\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Check if output file already exists, if so, delete and create new file\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "    # Open in \"append\" mode to avoid overwriting the whole file after each modification\n",
    "    return open(directory + filename, \"a\")\n",
    "\n",
    "def get_filename_without_extension(file_path):\n",
    "    file_basename = os.path.basename(file_path)\n",
    "    filename_without_extension = file_basename.split('.')[0]\n",
    "    return filename_without_extension\n",
    "\n",
    "def close_output_file(file):\n",
    "   file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Set\n",
    "\n",
    "\n",
    "class TaintAnalysisAlgorithm:\n",
    "    def __init__(self, filename):\n",
    "        self.cfg = None\n",
    "        self.filename = filename\n",
    "\n",
    "        # Dictionnary containing all necessary parameters (safe, filter, etc)\n",
    "        self.tainted_params: Dict[str, List[int]] = {} # Format: key = param_type(safe/filter/etc) value = node_ids arary\n",
    "\n",
    "        # GEN and KILL dictionnaries\n",
    "        ## Dictionnary containing all tainted_gen nodes for a specific node\n",
    "        self.tainted_gen:  Dict[int, Set] = {} # Format (for all following dictionnaries): key = node_id, value = set of node_ids\n",
    "        ## Dictionnary containing all tainted_kill nodes for a specific node\n",
    "        self.tainted_kill: Dict[int, Set] = {}\n",
    "\n",
    "        # IN and OUT dictionnaries\n",
    "        ## Dictionnary containing all tainted_in nodes for a specific node\n",
    "        self.tainted_in: Dict[int, Set] = {}\n",
    "        ## Dictionnary containing all tainted_out nodes for a specific node\n",
    "        self.tainted_out: Dict[int, Set] = {}\n",
    "\n",
    "    def __init_tainted_params(self, taint_json_filename):\n",
    "        # Read the file and initialize the appropriate parameters in a dictionnary\n",
    "        taint_file = open(f'{taint_json_filename}.php.taint.json')\n",
    "        params = json.load(taint_file)\n",
    "\n",
    "        self.tainted_params = {\n",
    "            'defs': params['defs'],\n",
    "            'refs': params['refs'],\n",
    "            'pairs': params['pairs'],\n",
    "            'sinks': params['sinks'],\n",
    "            'filters': params['filters'],\n",
    "            'safes': params['safes'],\n",
    "            'sources': params['sources']\n",
    "        }\n",
    "\n",
    "    def __get_expr_nodes(self, expr_node_id):\n",
    "        # Simulate a do while in order to keep going down the cfg until all references/(nodes that arent operators) made in the expression are retrieved\n",
    "        ref_nodes = []\n",
    "\n",
    "        # do\n",
    "        ref_node_id, expr_id = self.cfg.get_op_hands(expr_node_id)\n",
    "\n",
    "        # Check if variable to not accidentally add constants like 1, 2, 3 etc.\n",
    "        # if self.cfg.get_type(ref_node_id) == \"Variable\":\n",
    "        #     ref_nodes.append(ref_node_id)\n",
    "\n",
    "        while self.cfg.get_type(expr_id) == \"BinOP\":\n",
    "            print(\"inside while\")\n",
    "            ref_node_id, expr_id = self.cfg.get_op_hands(expr_id)\n",
    "\n",
    "            if self.cfg.get_type(ref_node_id) == \"Variable\":\n",
    "                ref_nodes.append(ref_node_id)\n",
    "\n",
    "        # Since we're out of the binop while, then the last right side node is part of the expression\n",
    "        ref_nodes.append(expr_id)\n",
    "\n",
    "        return ref_nodes    \n",
    "\n",
    "    def __is_binOp_equal(self, node_id: int):\n",
    "        return self.cfg.get_type(node_id) == \"BinOP\" and self.cfg.get_image(node_id) == \"=\"\n",
    "\n",
    "    def get_nodes_tainted_gen(self, node_id):\n",
    "        gens_value = self.tainted_gen.get(node_id)\n",
    "        if gens_value is None:\n",
    "            self.tainted_gen[node_id] = set()\n",
    "\n",
    "        ## To determine if the definition is tainted, we need to check the right side of the definition, and we need to check EACH node involved (each reference)\n",
    "        ## Ex: For definition x = y + z + w +1, we need to check y, z and w. If AT LEAST one of them is tainted, then the definition is tainted\n",
    "        ## To do so, we need to check for BinOP nodes\n",
    "        if self.__is_binOp_equal(node_id):\n",
    "            var_node_id, expr_node_id = self.cfg.get_op_hands(node_id)\n",
    "\n",
    "             # EXPR part of the algo\n",
    "            if self.cfg.get_type(expr_node_id) == \"BinOP\":\n",
    "                # First condition to check is if the defined variable is part of the tainted definitions\n",
    "                if var_node_id in self.tainted_params['defs']:\n",
    "                    self.tainted_gen[node_id].add(var_node_id)\n",
    "            \n",
    "                # Second condition to check is separated in two parts, and we need all the references made in the expression\n",
    "                ref_nodes = []\n",
    "                ref_nodes = self.__get_expr_nodes(expr_node_id)\n",
    "                for ref_id in ref_nodes:\n",
    "                    for (definition, reference) in self.tainted_params['pairs']:\n",
    "                        # First we need to see if the reference is part of the given tainted def/ref pairs\n",
    "                        # Second we need to see of the associated reference is part of the tainted definitions, either by checking the given tainted pairs,\n",
    "                        ## or by checking if it has been tainted during the code execution (hence why we check the tainted_in)\n",
    "                        if ref_id == reference and (definition in self.tainted_params['defs'] or definition in self.tainted_in[expr_node_id]):\n",
    "                            self.tainted_gen[node_id].add(var_node_id)\n",
    "\n",
    "        elif node_id in self.tainted_params['sources']:\n",
    "            self.tainted_gen[node_id].add(node_id)\n",
    "            \n",
    "        ## If part of filter or safe, then not tainted (in which case, skip)\n",
    "        elif node_id in self.tainted_params['filters']:\n",
    "            self.tainted_gen[node_id] = set()\n",
    "        elif node_id in self.tainted_params['safes']:\n",
    "            self.tainted_gen[node_id] = set()\n",
    "    \n",
    "    def get_nodes_tainted_kill(self, node_id):\n",
    "        if self.__is_binOp_equal(node_id):\n",
    "            var_node_id = self.cfg.get_op_hands(node_id)[0]\n",
    "\n",
    "            # According to the algorithm, if the defined variable is tainted, then we kill it\n",
    "            if var_node_id in self.tainted_params['defs']:\n",
    "                kills_value = self.tainted_kill.get(node_id)\n",
    "                if kills_value is None:\n",
    "                    self.tainted_kill[node_id] = {var_node_id}\n",
    "                else:\n",
    "                    kills_value.add(var_node_id)\n",
    "\n",
    "    def get_taint_analysis(self, taint_json_filename, cfg: CFG):\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # Start by initializing the relevant parameters for the analysis in order to populate the gen and kill dictionnaries for each node\n",
    "        self.__init_tainted_params(taint_json_filename)\n",
    "\n",
    "        # Retrieve the nodeSet. The algorithm we have to implement cannot be done recursively like we usually do \n",
    "        ## At least we found it simpler to do in an iterative manner, so as to follow the given algorithm as closely as possible\n",
    "        ## So the nodeSet here is the list of all nodes in the cfg\n",
    "        node_set = self.cfg.get_node_ids()\n",
    "\n",
    "        for node_id in node_set:\n",
    "            # Initialize the gen and kill dictionnaries for the current node\n",
    "            self.get_nodes_tainted_gen(node_id)\n",
    "            self.get_nodes_tainted_kill(node_id)\n",
    "\n",
    "            # Initialize the in and out dictionnaries for the current node\n",
    "            ins_value = self.tainted_in.get(node_id)\n",
    "            if ins_value is None:\n",
    "                self.tainted_in[node_id] = set()\n",
    "\n",
    "            outs_value = self.tainted_out.get(node_id)\n",
    "            if outs_value is None:\n",
    "                self.tainted_out[node_id] = set()\n",
    "\n",
    "        changes = True\n",
    "        old_out: Dict[int, Set] = {}\n",
    "\n",
    "        while changes:\n",
    "            changes = False\n",
    "\n",
    "            for node_id in node_set:\n",
    "                # First, we get the node's predecessor\n",
    "                ## We noticed that in the case of CallEnd nodes, the get_parents doesnt return anything, but we found the fucntion get_call_begin\n",
    "                ## which gives us the corresponding CallBegin node, which is the parent\n",
    "                predecessors = [self.cfg.get_call_begin(node_id)] if self.cfg.get_type(node_id) == 'CallEnd' else self.cfg.get_parents(node_id)\n",
    "\n",
    "                # Then, then in of the current node is composed of the out of each of those predecessors\n",
    "                for pred in predecessors:\n",
    "                    # Union allows us to add all the content of the out set at once without iterating over it\n",
    "                    self.tainted_in[node_id] = self.tainted_in[node_id].union(self.tainted_out[pred])\n",
    "                \n",
    "                old_out[node_id] = self.tainted_out[node_id]\n",
    "\n",
    "                # IN - KILL (default value to empty set in case node not found in kill, for error handling)\n",
    "                in_kill_difference = self.tainted_in.get(node_id).difference(self.tainted_kill.get(node_id, set()))\n",
    "                # GEN union (IN - KILL)\n",
    "                self.tainted_out[node_id] = self.tainted_gen[node_id].union(in_kill_difference)\n",
    "\n",
    "                if self.tainted_out[node_id] != old_out[node_id]:\n",
    "                    changes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output file and reader\n",
    "cfg_reader = CFGReader()\n",
    "\n",
    "def get_refs_defs_pairs(directory):\n",
    "    part1_output_directory = \"output/part_1/\"\n",
    "    part_1_output_file = create_output_file(\"part_1_output_file.txt\", part1_output_directory)\n",
    "\n",
    "    # Retrieve filenames of all cfg in the specified directory\n",
    "    cfgFilenames = get_json_files('*.cfg.json', directory)\n",
    "\n",
    "    # Iterate over the filenames array once to visit all cfgs\n",
    "    for filename in cfgFilenames:\n",
    "        taint_filename =  get_filename_without_extension(filename)\n",
    "        print(filename)\n",
    "\n",
    "        # Load cfg in memory\n",
    "        cfg = cfg_reader.read_cfg(filename)\n",
    "\n",
    "        analyser = TaintAnalysisAlgorithm(filename)\n",
    "        analyser.get_taint_analysis(directory_to_analyze + taint_filename, cfg)\n",
    "\n",
    "        # Print output\n",
    "        part_1_output_file.write(f\"------------------------ File: {filename} ------------------------\\n\")\n",
    "        for node in cfg.get_node_ids():\n",
    "            print(f\"{node}: , IN: {analyser.tainted_in[node]}, OUT: {analyser.tainted_out[node]}\")\n",
    "\n",
    "    \n",
    "    close_output_file(part_1_output_file)\n",
    "\n",
    "directory_to_analyze = \"../part_1/\"\n",
    "get_refs_defs_pairs(directory_to_analyze)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
