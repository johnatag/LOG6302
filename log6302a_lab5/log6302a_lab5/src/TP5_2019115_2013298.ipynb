{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from code_analysis import CFGReader\n",
    "from code_analysis import CFG\n",
    "\n",
    "# Global variable - directory where cfg.json and .dot files generated by our code will be stored \n",
    "part1_output_directory = \"output/part_1/\"\n",
    "part2_output_directory = \"output/part_2/\"\n",
    "\n",
    "# Utility functions taken from TP1\n",
    "def get_json_files(extension, directory):\n",
    "   directory = Path(directory)\n",
    "   return [str(file) for file in directory.rglob(extension)]\n",
    "\n",
    "def create_output_file(filename, directory):\n",
    "    # Check if output directory exists, if not, create it\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Check if output file already exists, if so, delete and create new file\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "    # Open in \"append\" mode to avoid overwriting the whole file after each modification\n",
    "    return open(directory + filename, \"a\")\n",
    "\n",
    "def close_output_file(file):\n",
    "   file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Set\n",
    "\n",
    "\n",
    "class TaintAnalysisAlgorithm:\n",
    "    def __init__(self, filename):\n",
    "        self.cfg = None\n",
    "        self.filename = filename\n",
    "\n",
    "        # Dictionnary containing all necessary parameters (safe, filter, etc)\n",
    "        self.tainted_params: Dict[str, List[int]] = dict() # Format: key = param_type(safe/filter/etc) value = node_ids arary\n",
    "\n",
    "        # GEN and KILL dictionnaries\n",
    "        ## Dictionnary containing all tainted_gen nodes for a specific node\n",
    "        self.tainted_gen = Dict[int, Set()] = dict() # Format (for all following dictionnaries): key = node_id, value = set of node_ids\n",
    "        ## Dictionnary containing all tainted_kill nodes for a specific node\n",
    "        self.tainted_kill = Dict[int, Set()] = dict()\n",
    "\n",
    "        # IN and OUT dictionnaries\n",
    "        ## Dictionnary containing all tainted_in nodes for a specific node\n",
    "        self.tainted_in = Dict[int, Set()] = dict()\n",
    "        ## Dictionnary containing all tainted_out nodes for a specific node\n",
    "        self.tainted_out = Dict[int, Set()] = dict()\n",
    "\n",
    "    def __init_tainted_params(self, taint_json_filename):\n",
    "        # Read the file and initialize the appropriate parameters in a dictionnary\n",
    "        params = json.loads(taint_json_filename)\n",
    "        self.tainted_params = {\n",
    "            'defs': params['defs'],\n",
    "            'refs': params['refs'],\n",
    "            'pairs': params['pairs'],\n",
    "            'sinks': params['sinks'],\n",
    "            'filters': params['filters'],\n",
    "            'safes': params['safes'],\n",
    "            'sources': params['sources']\n",
    "        }\n",
    "\n",
    "    def get_nodes_tainted_gen(self, var_node_id, expr_node_id):\n",
    "        ## To determine if the definition is tainted, we need to check the right side of the definition, and we need to check EACH node involved\n",
    "        ## Ex: For definition x = y + z + w +1, we need to check y, z and w. If AT LEAST one of them is tainted, then the definition is tainted\n",
    "        ## To do so, we need to check for BinOP nodes\n",
    "\n",
    "        # Populate tainted_gen according to the algorithm\n",
    "        ## If part of filter or safe, then not tainted (in which case, skip)\n",
    "        if expr_node_id in self.tainted_params['filters']:\n",
    "            pass\n",
    "        if expr_node_id in self.tainted_params['safes']:\n",
    "            pass\n",
    "        if expr_node_id in self.tainted_params['sources']:\n",
    "            self.tainted_gen[var_node_id, expr_node_id]['defs'].append() # append what???\n",
    "    \n",
    "    def get_nodes_tainted_kill(self, node_id):\n",
    "        pass\n",
    "\n",
    "    def get_taint_analysis(self, taint_json_filename):\n",
    "        is_binOP_equal = lambda child_node_id: self.cfg.get_type(child_node_id) == \"BinOP\" and self.cfg.get_image(child_node_id) == \"=\"\n",
    "\n",
    "        # Start by initializing the relevant parameters for the analysis in order to populate the gen and kill dictionnaries for each node\n",
    "        self.__init_tainted_params(taint_json_filename)\n",
    "\n",
    "        # Retrieve the nodeSet. The algorithm we have to implement cannot be done recursively like we usually do \n",
    "        ## At least we found it simpler to do in an iterative manner, so as to follow the given algorithm as closely as possible\n",
    "        ## So the nodeSet here is the list of all nodes in the cfg\n",
    "        node_set = self.cfg.get_node_ids()\n",
    "\n",
    "        for node_id in node_set:\n",
    "            # Only check the taint for definitions (since we are implementing the possibly tainted definitions algorithm):\n",
    "            ## Check if the node is BinOP and if child node is an '='\n",
    "            if is_binOP_equal(node_id):\n",
    "                # Left child is the variable, right child is the value/expression\n",
    "                variable_node_id, expression_node_id = self.cfg.get_op_hands(node_id)\n",
    "\n",
    "                # Initialize the gen and kill dictionnaries for the current node\n",
    "                self.get_nodes_tainted_gen(variable_node_id, expression_node_id)\n",
    "\n",
    "                # Initialize the in and out dictionnaries for the current node\n",
    "                self.tainted_in[variable_node_id] = set()\n",
    "                self.tainted_out[variable_node_id] = set()\n",
    "\n",
    "                # Initialize and populate the gen and kill for the current node\n",
    "                self.get_nodes_tainted_gen(node_id)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
