{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authors\n",
    "\n",
    "- Ikram Kohil, 2019115\n",
    "- Johnatan Gao, 2013298"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taint Analysis\n",
    "In this lab, we will be implementing taint analysis to ensure that all data coming from the outside (user inputs) do not reach critical parts of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementation and tests\n",
    "\n",
    "In this first part we will implement the teint analysis algorithm called: Possibly Teinted Definitions. We will then test the implementation on four examples in the folder **part_1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Possibly Tainted Definitions\n",
    "\n",
    "According to class notes, there are a couple of variables/concepts that we need to define in order to implement the conceptual algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "in\\_taintedDefs: V → \\Rho(DEFS)\n",
    "$$\n",
    "$$\n",
    "out\\_taintedDefs: V → \\Rho(DEFS)\n",
    "$$\n",
    "\n",
    "In this statement:\n",
    "\n",
    "- V: This typically represents a set or type of variables within the context of a programming language or a system. Variables can be anything from integers, strings, objects, etc., depending on the language or system under consideration.\n",
    "- P(DEFS): P represents the power set, which is the set of all subsets of a given set. DEFS is a set of definitions. So, P(DEFS) would be the power set of the set of definitions. In this context, it suggests that for each variable in V, there is a set of definitions (DEFS) associated with it, and in_taintedDefs maps each variable in V to a subset of its associated definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "in\\_taintedDefs(v) = \\bigcup_{p \\in preds(node)} out\\_taintedDefs(p)\n",
    "$$\n",
    "\n",
    "This equation defines the behavior of the in_taintedDefs function. It states that the in_taintedDefs for a variable v is the union (⋃) of the out_taintedDefs for all predecessors (preds(node)) of a given node. In other words, to compute the in_taintedDefs for a variable at a particular node, you take the union of the out_taintedDefs for all nodes that flow into that node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "tainted\\_GEN[node] = \n",
    "\\left\\{\n",
    "  \\begin{array}{ll}\n",
    "    \\ {d_i \\in defs[node]  | \\exists(d_j, r_k) \\in defRefChains | (r_k \\in refs[node]), (d_j \\in in\\_tainted[node])} &\\text{ if } (node \\in EXPR)\\ \\\\\n",
    "\n",
    "    \\ {d_i \\in defs[node]} & \\text{ if } (node \\in SOURCES) \\\\\n",
    "\n",
    "    \\emptyset & \\text{ if } (node \\in FILTERS) \\\\\n",
    "    \n",
    "    \\emptyset & \\text{ if } (node \\in SAFESET)\n",
    "  \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "In this statement, we are trying to populate our GEN array. For each node in our CFG, we check for four conditions:\n",
    "- If the node is part of the FILTERS set, then the tainted_gen for this node is empty\n",
    "- If the node is part of the SAFESET set, then the tainted_gen for this node is empty as well\n",
    "- If the node is part of the SOURCES set, then the tainted_gen for this node is the definition for this node\n",
    "- If the node is part of the EXPR set (in other words, is an expression), then we will:\n",
    "  - Take the defintion for this node, if it exists\n",
    "  - Take the definition/reference pair for this node, if it exists\n",
    "  - Create a pair of (reference, definition), if the reference is part of our reference set and definition is part of the in_tainted set for this node\n",
    "  \n",
    "In other words, \n",
    "1. Check if node is a definition: First, determine if the current node is a definition.\n",
    "\n",
    "2. If the node is a definition and the right side is a source: If the node is indeed a definition, and its right side is a source, then mark the definition as tainted. This means that the definition corresponds to a value that is considered tainted or untrusted.\n",
    "\n",
    "3. If the node is a definition and it corresponds to a filter or safe: If the node is a definition but corresponds to a filter or safe, then no action is taken. This implies that the definition is associated with a value that is considered safe or filtered, so it doesn't need further processing.\n",
    "\n",
    "4. If the node is a definition and the right side is an expression: If the node is a definition and its right side is an expression, further investigation is needed.\n",
    "Check if any references in the expression are tainted: Examine all references in the expression associated with the definition. If any of these references are tainted (i.e., marked as untrusted), then the definition is also considered tainted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "tainted\\_KILL[node] = {d_k | (var(d_k) = var(d_m)) ^ (d_m \\in defs[node] )}\n",
    "$$\n",
    "\n",
    "In this statement, we are trying to populate the kill set. Essentially, everytime we detect a definition OR a redefinition, we must add it to our tainted_kill set for this particular node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from code_analysis import CFGReader\n",
    "from code_analysis import CFG\n",
    "\n",
    "# Global variable - directory where cfg.json and .dot files generated by our code will be stored \n",
    "part1_output_directory = \"output/part_1/\"\n",
    "part2_output_directory = \"output/part_2/\"\n",
    "\n",
    "# Utility functions taken from TP1\n",
    "def get_json_files(extension, directory):\n",
    "   directory = Path(directory)\n",
    "   return [str(file) for file in directory.rglob(extension)]\n",
    "\n",
    "def create_output_file(filename, directory):\n",
    "    # Check if output directory exists, if not, create it\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Check if output file already exists, if so, delete and create new file\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "    # Open in \"append\" mode to avoid overwriting the whole file after each modification\n",
    "    return open(directory + filename, \"a\")\n",
    "\n",
    "def close_output_file(file):\n",
    "   file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Set\n",
    "\n",
    "\n",
    "class TaintAnalysisAlgorithm:\n",
    "    def __init__(self, filename):\n",
    "        self.cfg = None\n",
    "        self.filename = filename\n",
    "\n",
    "        # Dictionnary containing all necessary parameters (safe, filter, etc)\n",
    "        self.tainted_params: Dict[str, List[int]] = dict() # Format: key = param_type(safe/filter/etc) value = node_ids arary\n",
    "\n",
    "        # GEN and KILL dictionnaries\n",
    "        ## Dictionnary containing all tainted_gen nodes for a specific node\n",
    "        self.tainted_gen = Dict[int, Set()] = dict() # Format (for all following dictionnaries): key = node_id, value = set of node_ids\n",
    "        ## Dictionnary containing all tainted_kill nodes for a specific node\n",
    "        self.tainted_kill = Dict[int, Set()] = dict()\n",
    "\n",
    "        # IN and OUT dictionnaries\n",
    "        ## Dictionnary containing all tainted_in nodes for a specific node\n",
    "        self.tainted_in = Dict[int, Set()] = dict()\n",
    "        ## Dictionnary containing all tainted_out nodes for a specific node\n",
    "        self.tainted_out = Dict[int, Set()] = dict()\n",
    "\n",
    "    def __init_tainted_params(self, taint_json_filename):\n",
    "        # Read the file and initialize the appropriate parameters in a dictionnary\n",
    "        params = json.loads(taint_json_filename)\n",
    "        self.tainted_params = {\n",
    "            'defs': params['defs'],\n",
    "            'refs': params['refs'],\n",
    "            'pairs': params['pairs'],\n",
    "            'sinks': params['sinks'],\n",
    "            'filters': params['filters'],\n",
    "            'safes': params['safes'],\n",
    "            'sources': params['sources']\n",
    "        }\n",
    "\n",
    "    def get_nodes_tainted_gen(self, var_node_id, expr_node_id):\n",
    "        ## To determine if the definition is tainted, we need to check the right side of the definition, and we need to check EACH node involved\n",
    "        ## Ex: For definition x = y + z + w +1, we need to check y, z and w. If AT LEAST one of them is tainted, then the definition is tainted\n",
    "        ## To do so, we need to check for BinOP nodes\n",
    "\n",
    "        # Populate tainted_gen according to the algorithm\n",
    "        ## If part of filter or safe, then not tainted (in which case, skip)\n",
    "        if expr_node_id in self.tainted_params['filters']:\n",
    "            pass\n",
    "        if expr_node_id in self.tainted_params['safes']:\n",
    "            pass\n",
    "        if expr_node_id in self.tainted_params['sources']:\n",
    "            self.tainted_gen[var_node_id, expr_node_id]['defs'].append() # append what???\n",
    "    \n",
    "    def get_nodes_tainted_kill(self, node_id):\n",
    "        pass\n",
    "\n",
    "    def get_taint_analysis(self, taint_json_filename):\n",
    "        is_binOP_equal = lambda child_node_id: self.cfg.get_type(child_node_id) == \"BinOP\" and self.cfg.get_image(child_node_id) == \"=\"\n",
    "\n",
    "        # Start by initializing the relevant parameters for the analysis in order to populate the gen and kill dictionnaries for each node\n",
    "        self.__init_tainted_params(taint_json_filename)\n",
    "\n",
    "        # Retrieve the nodeSet. The algorithm we have to implement cannot be done recursively like we usually do \n",
    "        ## At least we found it simpler to do in an iterative manner, so as to follow the given algorithm as closely as possible\n",
    "        ## So the nodeSet here is the list of all nodes in the cfg\n",
    "        node_set = self.cfg.get_node_ids()\n",
    "\n",
    "        for node_id in node_set:\n",
    "            # Only check the taint for definitions (since we are implementing the possibly tainted definitions algorithm):\n",
    "            ## Check if the node is BinOP and if child node is an '='\n",
    "            if is_binOP_equal(node_id):\n",
    "                # Left child is the variable, right child is the value/expression\n",
    "                variable_node_id, expression_node_id = self.cfg.get_op_hands(node_id)\n",
    "\n",
    "                # Initialize the gen and kill dictionnaries for the current node\n",
    "                self.get_nodes_tainted_gen(variable_node_id, expression_node_id)\n",
    "\n",
    "                # Initialize the in and out dictionnaries for the current node\n",
    "                self.tainted_in[variable_node_id] = set()\n",
    "                self.tainted_out[variable_node_id] = set()\n",
    "\n",
    "                # Initialize and populate the gen and kill for the current node\n",
    "                self.get_nodes_tainted_gen(node_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
